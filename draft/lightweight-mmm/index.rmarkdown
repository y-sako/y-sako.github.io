---
title: "LightWeightMMMをRobynサンプルデータで試す"
author: "y-sako"
date: "2024-04-15"
categories: [VSCode, R]
---


## セットアップ


```{r}
if (!require("pacman")) install.packages("pacman"); library(pacman)
p_load(tidyverse)
# p_load(magrittr)
p_load(janitor)
p_load(Robyn)
p_load(reactable)
p_load(DT)
p_load(reticulate) # remotes::install_github("rstudio/reticulate")
# install tidyverse

# # for systemfonts
# sudo apt-get install libfontconfig1-dev
# sudo apt-get install libharfbuzz-dev libfribidi-dev
# # for ragg
# sudo apt-get install libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev

# install.packages("tidyverse")

# install Robyn

# # for systemfonts
# sudo apt-get install libfontconfig1-dev
# sudo apt-get install libharfbuzz-dev libfribidi-dev
# # for ragg
# sudo apt-get install libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev

# install.packages("Robyn")
# # for nloptr
# sudo apt-get install cmake

# install.packages("rstan")
# # 容量注意
```


## データ


```{r}
# Robynのサンプルデータ
dat_robyn = 
  dt_simulated_weekly %>% 
  tibble() %>% 
  clean_names() %>% 
  select(
    week = date,              
    revenue,
    # paid
    tv_cost = tv_s,
    ooh_cost = ooh_s,           
    print_cost = print_s,
    facebook_cost = facebook_s,
    facebook_impression = facebook_i,
    search_cost = search_s,
    search_click = search_clicks_p,
    newsletter_cost = newsletter,
    # base
    competitor_sales = competitor_sales_b,
    events = events
  ) %>% 
  mutate(event_1 = case_when(events == "event1" ~ 1, .default = 0)) %>% 
  mutate(event_2 = case_when(events == "event2" ~ 1, .default = 0)) %>% 
  select(-events)

dat_robyn %>% 
  head() %>% reactable()

# 変数マスタ
mst_vars = tibble::tribble(
  ~var_category, ~var_type,     ~value_type,  ~var_name,
  "time",        "week",        "week",       "week",
  "dep_var",     "dep_var",     "revenue",    "revenue",
  "paid_media",  "tv",          "cost",       "tv_cost",
  "paid_media",  "ooh",         "cost",       "ooh_cost",
  "paid_media",  "print",       "cost",       "print_cost",
  "paid_media",  "facebook",    "cost",       "facebook_cost",
  "paid_media",  "facebook",    "imp",        "facebook_impression",
  "paid_media",  "search",      "cost",       "search_cost",
  "paid_media",  "search",      "click",      "search_click",
  "paid_media",  "newsletter",  "cost",       "newsletter_cost",
  "baseline",    "competitor",  "sales",      "competitor_sales",
  "baseline",    "event_1",     "flag",       "event_1",
  "baseline",    "event_2",     "flag",       "event_2",
) %>% 
  mutate(mod_flag = case_when(
    var_name %in% c(
      "tv_cost",
      "ooh_cost",
      "print_cost",
      "facebook_impression",
      "search_click",
      "newsletter_cost",
      "competitor_sales",
      "event_1",
      "event_2"
    ) ~ 1,
    .default = 0
  ))

mst_vars %>% reactable()

lst_paid_media_vars = 
  mst_vars %>% 
  filter(var_category == "paid_media", 
         mod_flag == 1) %>% 
  pull(var_name)

lst_paid_media_cost = 
  mst_vars %>% 
  filter(value_type == "cost") %>% 
  pull(var_name)

lst_ctrl_vars = 
  mst_vars %>% 
  filter(var_category != "paid_media", 
         mod_flag == 1) %>% 
  pull(var_name)
```


## モデリング


```{python}

# !pip install pandas
# !pip install polars
# !pip install pyarrow
# !pip install matplotlib
# !pip install jax
# !pip install numpyro
# !pip install arviz
# !pip install itables
# !pip install lightweight_mmm
# # sudo apt-get install libhdf5-serial-dev

# セットアップ
## ライブラリ
import pathlib 
import os
import pandas as pd
import polars as pl
import jax.numpy as jnp
import jax
import numpyro
import numpy as np
from matplotlib import pyplot as plt
from lightweight_mmm import optimize_media
from lightweight_mmm import plot
from lightweight_mmm import preprocessing
from lightweight_mmm import utils
from lightweight_mmm import lightweight_mmm
import arviz as az
from itables import show

## シードを固定
SEED = 777

dat_mod = r.dat_robyn
lst_paid_media_vars = r.lst_paid_media_vars
lst_paid_media_cost = r.lst_paid_media_cost
lst_ctrl_vars = r.lst_ctrl_vars

data_size = len(dat_mod)

target = jnp.array(dat_mod["revenue"])
media_data = jnp.array(dat_mod[lst_paid_media_vars])
cost_data = jnp.array(dat_mod[lst_paid_media_cost])
costs = jnp.sum(media_data, axis=0)
extra_features = jnp.array(dat_mod[lst_ctrl_vars])

#%%

# 学習期間と検証期間で分割
split_point = data_size - 13
media_data_train = media_data[:split_point, ...]
media_data_test = media_data[split_point:, ...]
extra_features_train = extra_features[:split_point, ...]
extra_features_test = extra_features[split_point:, ...]
target_train = target[:split_point]
# スケーラー
media_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)
extra_features_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)
target_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)
cost_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)
# スケーリング
media_data_train = media_scaler.fit_transform(media_data_train)
extra_features_train = extra_features_scaler.fit_transform(extra_features_train)
target_train = target_scaler.fit_transform(target_train)
costs = cost_scaler.fit_transform(costs)

#%%
# モデルパス
path_model = pathlib.Path("/workspace/draft/lightweight-mmm/model/LMMM.pkl")

#%%
if path_model.exists():
    mmm = utils.load_model(file_path=str(path_model))
else:
    # モデルの設定
    mmm = lightweight_mmm.LightweightMMM(model_name="hill_adstock")
    # MCMCの設定
    N_CHAINS = 2
    number_warmup = 2000
    number_samples = 2000
    # モデルの推定
    mmm.fit(
        media=media_data_train,
        media_prior=costs,
        target=target_train,
        extra_features=extra_features_train,
        number_warmup=number_warmup,
        number_samples=number_samples,
        number_chains=N_CHAINS,
        seed=SEED
        )
    # モデルの保存
    utils.save_model(media_mix_model=mmm, file_path=str(path_model))
    
mmm.print_summary()
# dat_summary = az.summary(mmm._mcmc)
# show(dat_summary)

# # # !pip install IPython
# from IPython.display import display, Latex, HTML
# import IPython
# show(dat_summary)



# HTML(show(dat_summary))

# dat_summary.to_html()

# print(show(dat_summary))

# %%

# 貢献度分解
contribution_df = plot.create_media_baseline_contribution_df(
    media_mix_model=mmm,
    target_scaler=target_scaler,
    )
contribution_df = pl.from_pandas(contribution_df)
contribution_df = contribution_df.select([
  pl.col("period"), 
  pl.col("avg_prediction"), 
  pl.col("^*contribution$")
  ])
contribution_df = contribution_df.melt(
  id_vars = ["period", "avg_prediction"],
  value_vars = contribution_df.select([pl.col("^*contribution$")]).columns
  )

target_df = pl.DataFrame(
  pd.DataFrame(
    target_scaler.inverse_transform(target_train),
    columns=["target"]
    )
  ).with_row_index(
    name="period", 
    offset=1
  ).with_columns(
    pl.col("period").cast(pl.Int64)
  )

output_df = contribution_df.join(
  target_df, 
  on="period", 
  how="left"
  ).with_columns(
    (pl.col("target")/pl.col("avg_prediction")).alias("scaleback_rate")
  ).with_columns(
    (pl.col("value")*pl.col("scaleback_rate")).alias("scaleback_value")
  ).select([
    "period",
    "variable",
    "scaleback_value"
  ]).rename({
    "scaleback_value": "value"
  })

output_df = output_df.to_pandas()

#%%
media_contribution, roi_hat = mmm.get_posterior_metrics(
  target_scaler=target_scaler, 
  cost_scaler=cost_scaler
  )

pd.DataFrame(media_contribution)
pd.DataFrame(roi_hat)

fig = plot.plot_model_fit(mmm, target_scaler=target_scaler)
fig.show()
plt.show()

print(fig)

# #%%
# help(lightweight_mmm)

# # %%
# for item in dir(lightweight_mmm):
#     print(item)

# # %%
# [item for item in dir(lightweight_mmm.LightweightMMM)]

# # %%
# mmm.model_name
# %%

# contribution_colname = [col for col in raw_contribution_df.columns.to_list() if col.endswith("contribution")]
# contribution_colname
# # .str.endswith("contribution")

# # 貢献度の合計が合致しているかを確認
# contribution_df.group_by("period").agg([
#     pl.col("avg_prediction").unique().first(),
#     pl.col("value").sum().alias("total")
# ]).sort(by="period")

# # チェック
# contribution_df.join(
#   target_df, 
#   on="period", 
#   how="left"
#   ).with_columns(
#     (pl.col("target")/pl.col("avg_prediction")).alias("scaleback_rate")
#   ).with_columns(
#     (pl.col("value")*pl.col("scaleback_rate")).alias("scaleback_value")
#   ).group_by("period").agg([
#     pl.col("avg_prediction").unique().first(),
#     pl.col("target").unique().first(),
#     pl.col("scaleback_value").sum().alias("total")
#   ]).sort(by="period")
```

```{r}
# p_load(reticulate)
# py$dat_summary %>% 
#   rownames_to_column("parameter") %>% 
#   tibble() %>% 
#   filter(str_detect(parameter, "^media_transformed")) %>% 
#   select(parameter, r_hat) %>% 
#   datatable()
```

```{r}

mst_week = 
  dat_robyn %>% 
  select(week) %>% 
  mutate(t = row_number())

mst_media = 
  tibble(paid_media_vars = lst_paid_media_vars) %>% 
  separate(paid_media_vars, "_", into = c("media", "vars")) %>% 
  mutate(channel_no = row_number() - 1) %>% 
  mutate(channel_no = str_c("channel_", channel_no))

dat_output = 
  py$output_df %>% 
  tibble() %>% 
  mutate(variable = str_remove(variable, "contribution")) %>% 
  mutate(variable = str_remove(variable, "\\s")) %>% 
  left_join(mst_media, by = c("variable" = "channel_no")) %>% 
  select(-variable) %>% 
  rename(variable = media) %>% 
  left_join(mst_week, by = c("period" = "t"))

dat_output %>% 
  # mutate(category = 
  #          factor(category, levels = c("paid_media", "baseline"))) %>% 
  ggplot() + 
  geom_bar(aes(x=week, y=value, fill=variable, group=variable), 
           stat="identity", alpha=0.5) +
  scale_y_continuous(labels = scales::comma_format())

dat_output %>% reactable
```


## Pyhtonテスト


```{python}
import matplotlib.pyplot as plt
plt.plot([1,2,3,4])
plt.show()
```

```{python}
plot.plot_model_fit(mmm, target_scaler=target_scaler).show()
```


## 環境をアップデート



```{r}
#| eval: false
#| echo: false
renv::snapshot()
```

```{python}
#| eval: false
#| echo: false
!pip freeze > requirements.txt
```
